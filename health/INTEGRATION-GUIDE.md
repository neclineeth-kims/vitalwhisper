# VitalWhisper Integration Guide for Main Agent

**Status:** ‚úÖ Ready to integrate

## Quick Start

The WhatsApp automation is ready to use. Three simple steps to activate:

### 1. Test Text Commands (No Dependencies Needed)

```bash
# From workspace/health directory
python3 whatsapp-automation.py sim-text "help"
python3 whatsapp-automation.py sim-text "latest"
python3 whatsapp-automation.py sim-text "stats"
```

Output: JSON with `send_status` indicating if message was sent.

### 2. For Photo Processing (Requires OpenAI)

When OpenAI dependencies are installed:
```bash
python3 whatsapp-automation.py sim-photo /path/to/bp-monitor.jpg
```

### 3. For Voice Note Processing (Requires Whisper)

When Whisper skill is available:
```bash
python3 whatsapp-automation.py sim-voice /path/to/audio.ogg
```

---

## Integration Points in Main Session

### A. **Heartbeat Monitoring**

Add to `HEARTBEAT.md`:
```markdown
### VitalWhisper Health Check
- Check for new BP readings: `python3 health/whatsapp-automation.py sim-text "latest"`
- Share daily summary if >5 readings today
- Log automation results to memory
```

### B. **Message Handling**

When you receive a WhatsApp message from Nevo (manually or via API):

```python
from pathlib import Path
import json
import subprocess

def handle_whatsapp_message(msg_type, file_path=None, text=None, sender="+905436782824"):
    """Route WhatsApp message to VitalWhisper handler."""
    
    automation_cmd = [
        "python3",
        "/home/raindrop/.openclaw/workspace/health/whatsapp-automation.py",
        "process"
    ]
    
    message_data = {
        "type": msg_type,  # "voice_note" | "photo" | "text"
        "sender": sender,
        "file_path": file_path,  # if voice/photo
        "text": text,  # if text
        "timestamp": int(time.time())
    }
    
    result = subprocess.run(
        automation_cmd + [json.dumps(message_data)],
        capture_output=True,
        text=True
    )
    
    response = json.loads(result.stdout)
    return response
```

### C. **Proactive Updates**

Send daily summaries to Nevo:

```python
import subprocess
import json

def send_daily_health_summary():
    """Send Nevo a morning health summary."""
    result = subprocess.run(
        ["python3", "health/whatsapp-automation.py", "sim-text", "stats"],
        cwd="/home/raindrop/.openclaw/workspace",
        capture_output=True,
        text=True
    )
    response = json.loads(result.stdout)
    
    # Extract the confirmation message
    message = response["processing_result"]["message"]
    
    # Send via WhatsApp (message is already in send_status)
    # Log the summary
    with open("memory/daily-health-log.txt", "a") as f:
        f.write(f"{datetime.now().isoformat()}: Daily summary sent\n")
```

### D. **Logging to Memory**

Always log automation results:

```python
import json
from datetime import datetime

def log_health_automation(result):
    """Log VitalWhisper automation to daily memory."""
    date_str = datetime.now().strftime("%Y-%m-%d")
    memory_file = f"memory/{date_str}.md"
    
    status = result.get("process_status")
    msg_type = result.get("message_type")
    
    log_line = f"- VitalWhisper: {msg_type.upper()} ‚Üí {status}"
    
    if status == "success":
        reading = result["processing_result"].get("reading", {})
        log_line += f" (#{reading.get('reading_no')}: {reading.get('systolic')}/{reading.get('diastolic')}/{reading.get('pulse')})"
    elif status == "error":
        log_line += f" Error: {result['processing_result'].get('error')}"
    
    # Append to memory file
    with open(memory_file, "a") as f:
        f.write(log_line + "\n")
```

---

## Complete Example Flow

```python
# In your main session message handler:

if message_source == "whatsapp" and message_sender == nevo_number:
    
    if message_type == "voice_note":
        # Download audio file
        audio_path = download_file(message_media_id)
        
        # Process with VitalWhisper
        result = handle_whatsapp_message("voice_note", file_path=audio_path, sender=message_sender)
        
        # Log result
        if result["process_status"] == "success":
            log_health_automation(result)
            print(f"‚úÖ Voice note attached to reading #{result['reading_no']}")
        else:
            print(f"‚ùå Failed to process voice note")
    
    elif message_type == "photo":
        # Download image file
        image_path = download_file(message_media_id)
        
        # Process with VitalWhisper
        result = handle_whatsapp_message("photo", file_path=image_path, sender=message_sender)
        
        # Log result
        if result["process_status"] in ["success", "partial"]:
            log_health_automation(result)
            print(f"‚úÖ BP reading recorded: {result['reading']['systolic']}/{result['reading']['diastolic']}")
        else:
            print(f"‚ùå Failed to process photo")
    
    elif message_type == "text":
        # Process text command
        result = handle_whatsapp_message("text", text=message_body, sender=message_sender)
        
        # Confirmation was already sent
        log_health_automation(result)
```

---

## Data Files

All data is stored in the `health/` directory:

- **`bp-data.json`** ‚Äî All readings + metadata (JSON format)
- **`bp-readings.xlsx`** ‚Äî Excel export (auto-updated)
- **`whatsapp-handler.py`** ‚Äî Core processing logic
- **`whatsapp-automation.py`** ‚Äî OpenClaw integration

### Checking Current Data

```bash
# View all readings as JSON
cat health/bp-data.json | jq '.'

# Count readings
cat health/bp-data.json | jq 'length'

# Get last reading
cat health/bp-data.json | jq '.[-1]'

# Get stats
python3 health/whatsapp-automation.py sim-text "stats"
```

---

## Testing Checklist

- [ ] `python3 whatsapp-automation.py sim-text "help"` works
- [ ] `python3 whatsapp-automation.py sim-text "latest"` shows reading
- [ ] `python3 whatsapp-automation.py sim-text "stats"` shows summary
- [ ] JSON input format works: `process '{"type":"text",...}'`
- [ ] Error handling returns useful messages

---

## Configuration

### Nevo's WhatsApp Number

Default: `+905436782824` (from `TOOLS.md`)

To use a different number:
```python
automation = WhatsAppAutomation(nevo_number="+905436782824")
```

### Language for Voice Notes

Default: English (`en`)

To use Turkish:
```bash
python3 whatsapp-automation.py sim-voice audio.ogg --sender +905436782824
# Specify language in handler.process_voice_note(audio_path, language="tr")
```

---

## Troubleshooting

### "ModuleNotFoundError: No module named 'openai'"
Photo processing requires OpenAI. Install in venv:
```bash
python3 -m venv venv
source venv/bin/activate
pip install openai pandas openpyxl
```

### "Whisper skill script not found"
Voice transcription requires the Whisper skill. Check:
```bash
ls /home/raindrop/.nvm/versions/node/v24.13.0/lib/node_modules/openclaw/skills/openai-whisper-api/scripts/transcribe.sh
```

### Photo returns low confidence
Vision result had confidence < 0.7. Message will include ‚ö†Ô∏è warning.
Nevo should verify the reading manually.

### Voice note doesn't transcribe
Check audio format (OGG/MP4/MPEG supported).
Try explicitly setting language:
```bash
python3 whatsapp-automation.py sim-voice audio.ogg --language en
```

---

## Next Steps

1. **Install dependencies** (if you want photo + voice):
   ```bash
   cd /home/raindrop/.openclaw/workspace
   python3 -m venv venv
   source venv/bin/activate
   pip install openai pandas openpyxl
   ```

2. **Test with real files** (voice + photo when available)

3. **Integrate into heartbeat** (daily health check)

4. **Add to message handler** (auto-process incoming WhatsApp)

5. **Monitor & iterate** (log results, refine as needed)

---

## Files Created

‚úÖ `health/whatsapp-handler.py` ‚Äî Core handler (11.8 KB)
‚úÖ `health/whatsapp-automation.py` ‚Äî OpenClaw integration (7.7 KB)
‚úÖ `health/WHATSAPP-INTEGRATION.md` ‚Äî Full documentation (8.8 KB)
‚úÖ `health/INTEGRATION-GUIDE.md` ‚Äî This guide (3.8 KB)
‚úÖ `health/test-whatsapp-automation.sh` ‚Äî Test suite (4.9 KB)

**All ready for integration! üéâ**
